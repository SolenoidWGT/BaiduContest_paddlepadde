{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from __future__ import print_function\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "CLASS_DIM = 2\n",
    "EMB_DIM = 128\n",
    "HID_DIM = 512\n",
    "STACKED_NUM = 3\n",
    "BATCH_SIZE = 128\n",
    "USE_GPU = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pd.read_csv('busdata.csv',chunksize=100000,usecols=[1,3,5,6,7,8,9])\n",
    "frames=[]\n",
    "for chunk in reader:\n",
    "    frames.append(chunk[(chunk.O_BUSNAME==80187)&(chunk.O_SPEED>0)])\n",
    "result = pd.concat(frames)\n",
    "result['O_TIME']=pd.to_datetime(result['O_TIME'],format=\"%H:%M:%S\")\n",
    "result=result.sort_values(by='O_TIME')\n",
    "result.set_index('O_TIME')\n",
    "result.to_csv(\"238night_80187_result_sort.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O_LINENO                      2390\n",
       "O_BUSNAME                    80187\n",
       "O_DATE                  2016-01-01\n",
       "O_TIME         1900-01-01 00:00:02\n",
       "O_LONGITUDE                7404.54\n",
       "O_LATITUDE                 2506.38\n",
       "O_SPEED                         31\n",
       "Name: 1965, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900-01-01 00:01:37\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "time=result.iloc[0,3]\n",
    "time=pd.to_datetime(time,format=\"%H:%M:%S\")\n",
    "print(time)\n",
    "print(type(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stacked_lstm_net(data, input_dim, class_dim, emb_dim, hid_dim, stacked_num):\n",
    "\n",
    "    emb = fluid.layers.embedding(dataframe\n",
    "        input=data, size=[input_dim, emb_dim], is_sparse=True)\n",
    "\n",
    "    fc1 = fluid.layers.fc(input=emb, size=hid_dim)\n",
    "    lstm1, cell1 = fluid.layers.dynamic_lstm(input=fc1, size=hid_dim)\n",
    "3\n",
    "    inputs = [fc1, lstm1]\n",
    "\n",
    "    for i in range(2, stacked_num + 1):\n",
    "        fc = fluid.layers.fc(input=inputs, size=hid_dim)\n",
    "        lstm, cell = fluid.layers.dynamic_lstm(\n",
    "            input=fc, size=hid_dim, is_reverse=(i % 2) == 0)\n",
    "        inputs = [fc, lstm]\n",
    "\n",
    "    fc_last = fluid.layers.sequence_pool(input=inputs[0], pool_type='max')\n",
    "    lstm_last = fluid.layers.sequence_pool(input=inputs[1], pool_type='max')\n",
    "\n",
    "    prediction = fluid.layers.fc(\n",
    "        input=[fc_last, lstm_last], size=class_dim, act='softmax')\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#接下来我们定义预测程序（inference_program）。dataframe预测程序使用convolution_net来对fluid.layer.data的输入进行预测。\n",
    "def inference_program(word_dict):\n",
    "    data = fluid.layers.data(\n",
    "        name=\"words\", shape=[1], dtype=\"int64\", lod_level=1)\n",
    "    \n",
    "    dict_dim = len(word_dict)\n",
    "    \n",
    "    net = convolution_net(data, dict_dim, CLASS_DIM, EMB_DIM, HID_DIM)\n",
    "    # net = stacked_lstm_net(data, dict_dim, CLASS_DIM, EMB_DIM, HID_DIM, STACKED_NUM)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#我们这里定义了training_program。它使用了从inference_program返回的结果来计算误差。我们同时定义了优化函数optimizer_func。\n",
    "\n",
    "#因为是有监督的学习，训练集的标签也在paddle.layer.data中定义了。在训练过程中，交叉熵用来在paddle.layer.classification_cost中作为损失函数。\n",
    "\n",
    "#在测试过程中，分类器会计算各个输出的概率。第一个返回的数值规定为 损耗(cost)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_program(word_dict):\n",
    "    prediction = inference_program(word_dict)\n",
    "    \n",
    "    label = fluid.layers.data(name=\"label\", shape=[1], dtype=\"int64\")\n",
    "    #label定义的是监督学习中的标签，label对应的时数据集中名为“label”的列，维度是一维向量，类型时整型\n",
    "    #理解fluid.layers.data应该是一个存放数据的函数\n",
    "    \n",
    "    cost = fluid.layers.cross_entropy(input=prediction, label=label)\n",
    "    #定义训练的损失函数为交叉熵，输入为prediction和标签\n",
    "    avg_cost = fluid.layers.mean(cost)\n",
    "    \n",
    "    accuracy = fluid.layers.accuracy(input=prediction, label=label)\n",
    "    \n",
    "    return [avg_cost, accuracy]\n",
    "\n",
    "\n",
    "def optimizer_func():\n",
    "    return fluid.optimizer.Adagrad(learning_rate=0.002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义训练环境\n",
    "#定义您的训练是在CPU上还是在GPU上\n",
    "use_cuda = False\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义数据提供器\n",
    "#下一步是为训练和测试定义数据提供器。提供器读入一个大小为 BATCH_SIZE的数据。\n",
    "#paddle.dataset.imdb.train 每次会在乱序化后提供一个大小为BATCH_SIZE的数据，乱序化的大小为缓存大小buf_size。\n",
    "#注意：读取IMDB的数据可能会花费几分钟的时间，请耐心等待\n",
    "\n",
    "print(\"Loading IMDB word dict....\")\n",
    "word_dict = paddle.dataset.imdb.word_dict()\n",
    "\n",
    "print (\"Reading training data....\")\n",
    "train_reader = paddle.batch(\n",
    "    paddle.reader.shuffle(\n",
    "        paddle.dataset.imdb.train(word_dict), buf_size=25000),\n",
    "    batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构造训练器(trainer)\n",
    "#训练器需要一个训练程序和一个训练优化函数。\n",
    "\n",
    "trainer = fluid.Trainer(\n",
    "    train_func=partial(train_program, word_dict),\n",
    "    place=place,\n",
    "    optimizer_func=optimizer_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#提供数据\n",
    "#feed_order用来定义每条产生的数据和paddle.layer.data之间的映射关系。比如，imdb.train产生的第一列的数据对应的是words这个特征。\n",
    "feed_order = ['words', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify the directory path to save the parameters\n",
    "#事件处理器\n",
    "#回调函数event_handler在一个之前定义好的事件发生后会被调用。例如，我们可以在每步训练结束后查看误差。\n",
    "params_dirname = \"understand_sentiment_conv.inference.model\"\n",
    "\n",
    "def event_handler(event):\n",
    "    if isinstance(event, fluid.EndStepEvent):\n",
    "        print(\"Step {0}, Epoch {1} Metrics {2}\".format(\n",
    "                event.step, event.epoch, map(np.array, event.metrics)))\n",
    "\n",
    "        if event.step == 10:\n",
    "            trainer.save_params(params_dirname)\n",
    "            trainer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#开始训练\n",
    "#最后，我们传入训练循环数（num_epoch）和一些别的参数，调用 trainer.train 来开始训练。\n",
    "trainer.train(\n",
    "    num_epochs=1,\n",
    "    event_handler=event_handler,\n",
    "    reader=train_reader,\n",
    "    feed_order=feed_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构建预测器\n",
    "#传入inference_program和params_dirname来初始化一个预测器, params_dirname用来存放训练过程中的各个参数。\n",
    "inferencer = fluid.Inferencer(\n",
    "        infer_func=partial(inference_program, word_dict), param_path=params_dirname, place=place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_str = [\n",
    "    'read the book forget the movie', 'this is a great movie', 'this is very bad'\n",
    "]\n",
    "reviews = [c.split() for c in reviews_str]\n",
    "\n",
    "UNK = word_dict['<unk>']\n",
    "lod = []\n",
    "for c in reviews:\n",
    "    lod.append([word_dict.get(words, UNK) for words in c])\n",
    "\n",
    "base_shape = [[len(c) for c in lod]]\n",
    "\n",
    "tensor_words = fluid.create_lod_tensor(lod, base_shape, place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = inferencer.infer({'words': tensor_words})\n",
    "\n",
    "for i, r in enumerate(results[0]):\n",
    "    print(\"Predict probability of \", r[0], \" to be positive and \", r[1], \" to be negative for review \\'\", reviews_str[i], \"\\'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
